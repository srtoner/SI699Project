{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ff4f69db",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/stephentoner/miniconda3/envs/si699proj/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle as pkl\n",
    "import seaborn as sns\n",
    "\n",
    "import torch\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "# load config\n",
    "with open('config.json', 'r') as f:\n",
    "    config = json.load(f)\n",
    "cwd = os.getcwd()\n",
    "os.chdir(config['REPODIR'])\n",
    "import Utils as U\n",
    "# from Corpus import Corpus\n",
    "os.chdir(cwd)\n",
    "\n",
    "from collections import Counter, defaultdict\n",
    "import itertools\n",
    "\n",
    "\n",
    "from tqdm.auto import tqdm, trange\n",
    "from collections import Counter\n",
    "import random\n",
    "from torch import optim\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "sns.set_theme(style=\"dark\")\n",
    "import pickle as pkl\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import f1_score\n",
    "import nltk\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils.data.dataloader import default_collate\n",
    "\n",
    "torch.set_default_dtype(torch.float32)\n",
    "\n",
    "suffix = \"full\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ef9bc56c",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('sentence_embed.pkl', 'rb') as f:\n",
    "    embed = pkl.load(f)\n",
    "\n",
    "embed_df = pd.DataFrame(embed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3877e33e",
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_df = embed_df.rename(columns = {0: 'seqid', 1: 'passage_key', 2: 'sent_embeddings'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ec2a4fa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = U.load_file('data_vFFFF.pkl', 'pkl', config['DATADIR'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d08c9914",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "615a259c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author_id</th>\n",
       "      <th>author_name</th>\n",
       "      <th>book_id</th>\n",
       "      <th>gutenbergbookid</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>text_lines</th>\n",
       "      <th>authoryearofbirth</th>\n",
       "      <th>authoryearofdeath</th>\n",
       "      <th>downloads</th>\n",
       "      <th>subjects</th>\n",
       "      <th>topic</th>\n",
       "      <th>Sub_A</th>\n",
       "      <th>Sub_B</th>\n",
       "      <th>Sub_C</th>\n",
       "      <th>str_text_lines</th>\n",
       "      <th>passage_key</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2210</td>\n",
       "      <td>Verne, Jules</td>\n",
       "      <td>PG103</td>\n",
       "      <td>PG103</td>\n",
       "      <td>Around the World in Eighty Days</td>\n",
       "      <td>[“No.”, , “I will buy it of you.”, , “No.”, , ...</td>\n",
       "      <td>7736</td>\n",
       "      <td>1828.0</td>\n",
       "      <td>1905.0</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>{'Voyages around the world -- Fiction', 'Adven...</td>\n",
       "      <td>Fiction</td>\n",
       "      <td>Adventure stories</td>\n",
       "      <td>Voyages around the world</td>\n",
       "      <td>Fiction</td>\n",
       "      <td>7736</td>\n",
       "      <td>PG103_7736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2210</td>\n",
       "      <td>Verne, Jules</td>\n",
       "      <td>PG103</td>\n",
       "      <td>PG103</td>\n",
       "      <td>Around the World in Eighty Days</td>\n",
       "      <td>[Bombay, for which they were now detained at C...</td>\n",
       "      <td>3686</td>\n",
       "      <td>1828.0</td>\n",
       "      <td>1905.0</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>{'Voyages around the world -- Fiction', 'Adven...</td>\n",
       "      <td>Fiction</td>\n",
       "      <td>Adventure stories</td>\n",
       "      <td>Voyages around the world</td>\n",
       "      <td>Fiction</td>\n",
       "      <td>3686</td>\n",
       "      <td>PG103_3686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2210</td>\n",
       "      <td>Verne, Jules</td>\n",
       "      <td>PG103</td>\n",
       "      <td>PG103</td>\n",
       "      <td>Around the World in Eighty Days</td>\n",
       "      <td>[, “Well, Monsieur Fix,” said Passepartout, “h...</td>\n",
       "      <td>4386</td>\n",
       "      <td>1828.0</td>\n",
       "      <td>1905.0</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>{'Voyages around the world -- Fiction', 'Adven...</td>\n",
       "      <td>Fiction</td>\n",
       "      <td>Adventure stories</td>\n",
       "      <td>Voyages around the world</td>\n",
       "      <td>Fiction</td>\n",
       "      <td>4386</td>\n",
       "      <td>PG103_4386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2210</td>\n",
       "      <td>Verne, Jules</td>\n",
       "      <td>PG103</td>\n",
       "      <td>PG103</td>\n",
       "      <td>Around the World in Eighty Days</td>\n",
       "      <td>[but the intractable Fogg, as reserved as ever...</td>\n",
       "      <td>3836</td>\n",
       "      <td>1828.0</td>\n",
       "      <td>1905.0</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>{'Voyages around the world -- Fiction', 'Adven...</td>\n",
       "      <td>Fiction</td>\n",
       "      <td>Adventure stories</td>\n",
       "      <td>Voyages around the world</td>\n",
       "      <td>Fiction</td>\n",
       "      <td>3836</td>\n",
       "      <td>PG103_3836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2210</td>\n",
       "      <td>Verne, Jules</td>\n",
       "      <td>PG103</td>\n",
       "      <td>PG103</td>\n",
       "      <td>Around the World in Eighty Days</td>\n",
       "      <td>[“I am he.”, , “Is this man your servant?” add...</td>\n",
       "      <td>3536</td>\n",
       "      <td>1828.0</td>\n",
       "      <td>1905.0</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>{'Voyages around the world -- Fiction', 'Adven...</td>\n",
       "      <td>Fiction</td>\n",
       "      <td>Adventure stories</td>\n",
       "      <td>Voyages around the world</td>\n",
       "      <td>Fiction</td>\n",
       "      <td>3536</td>\n",
       "      <td>PG103_3536</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   author_id   author_name book_id gutenbergbookid  \\\n",
       "0       2210  Verne, Jules   PG103           PG103   \n",
       "1       2210  Verne, Jules   PG103           PG103   \n",
       "2       2210  Verne, Jules   PG103           PG103   \n",
       "3       2210  Verne, Jules   PG103           PG103   \n",
       "4       2210  Verne, Jules   PG103           PG103   \n",
       "\n",
       "                             title  \\\n",
       "0  Around the World in Eighty Days   \n",
       "1  Around the World in Eighty Days   \n",
       "2  Around the World in Eighty Days   \n",
       "3  Around the World in Eighty Days   \n",
       "4  Around the World in Eighty Days   \n",
       "\n",
       "                                                text  text_lines  \\\n",
       "0  [“No.”, , “I will buy it of you.”, , “No.”, , ...        7736   \n",
       "1  [Bombay, for which they were now detained at C...        3686   \n",
       "2  [, “Well, Monsieur Fix,” said Passepartout, “h...        4386   \n",
       "3  [but the intractable Fogg, as reserved as ever...        3836   \n",
       "4  [“I am he.”, , “Is this man your servant?” add...        3536   \n",
       "\n",
       "   authoryearofbirth  authoryearofdeath  downloads  \\\n",
       "0             1828.0             1905.0     2015.0   \n",
       "1             1828.0             1905.0     2015.0   \n",
       "2             1828.0             1905.0     2015.0   \n",
       "3             1828.0             1905.0     2015.0   \n",
       "4             1828.0             1905.0     2015.0   \n",
       "\n",
       "                                            subjects    topic  \\\n",
       "0  {'Voyages around the world -- Fiction', 'Adven...  Fiction   \n",
       "1  {'Voyages around the world -- Fiction', 'Adven...  Fiction   \n",
       "2  {'Voyages around the world -- Fiction', 'Adven...  Fiction   \n",
       "3  {'Voyages around the world -- Fiction', 'Adven...  Fiction   \n",
       "4  {'Voyages around the world -- Fiction', 'Adven...  Fiction   \n",
       "\n",
       "               Sub_A                     Sub_B    Sub_C str_text_lines  \\\n",
       "0  Adventure stories  Voyages around the world  Fiction           7736   \n",
       "1  Adventure stories  Voyages around the world  Fiction           3686   \n",
       "2  Adventure stories  Voyages around the world  Fiction           4386   \n",
       "3  Adventure stories  Voyages around the world  Fiction           3836   \n",
       "4  Adventure stories  Voyages around the world  Fiction           3536   \n",
       "\n",
       "  passage_key  \n",
       "0  PG103_7736  \n",
       "1  PG103_3686  \n",
       "2  PG103_4386  \n",
       "3  PG103_3836  \n",
       "4  PG103_3536  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df = pd.DataFrame(data)\n",
    "data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cb5aa6ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_df = embed_df.merge(data_df, how= 'left', left_on= 'passage_key', right_on = 'passage_key')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3640a2ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>seqid</th>\n",
       "      <th>passage_key</th>\n",
       "      <th>sent_embeddings</th>\n",
       "      <th>author_id</th>\n",
       "      <th>author_name</th>\n",
       "      <th>book_id</th>\n",
       "      <th>gutenbergbookid</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>text_lines</th>\n",
       "      <th>authoryearofbirth</th>\n",
       "      <th>authoryearofdeath</th>\n",
       "      <th>downloads</th>\n",
       "      <th>subjects</th>\n",
       "      <th>topic</th>\n",
       "      <th>Sub_A</th>\n",
       "      <th>Sub_B</th>\n",
       "      <th>Sub_C</th>\n",
       "      <th>str_text_lines</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>PG105_2371</td>\n",
       "      <td>[-0.40695864, 0.3818504, 0.060175154, -0.16981...</td>\n",
       "      <td>5049.0</td>\n",
       "      <td>Austen, Jane</td>\n",
       "      <td>PG105</td>\n",
       "      <td>PG105</td>\n",
       "      <td>Persuasion</td>\n",
       "      <td>[Croft’s next words explained it to be Mr Went...</td>\n",
       "      <td>2371.0</td>\n",
       "      <td>1775.0</td>\n",
       "      <td>1817.0</td>\n",
       "      <td>2778.0</td>\n",
       "      <td>{'Regency fiction', 'Ship captains -- Fiction'...</td>\n",
       "      <td>Fiction</td>\n",
       "      <td>Love stories</td>\n",
       "      <td>Young women</td>\n",
       "      <td>Psychological fiction</td>\n",
       "      <td>2371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>PG105_2371</td>\n",
       "      <td>[-0.33000952, 0.35164443, 0.05541102, -0.16663...</td>\n",
       "      <td>5049.0</td>\n",
       "      <td>Austen, Jane</td>\n",
       "      <td>PG105</td>\n",
       "      <td>PG105</td>\n",
       "      <td>Persuasion</td>\n",
       "      <td>[Croft’s next words explained it to be Mr Went...</td>\n",
       "      <td>2371.0</td>\n",
       "      <td>1775.0</td>\n",
       "      <td>1817.0</td>\n",
       "      <td>2778.0</td>\n",
       "      <td>{'Regency fiction', 'Ship captains -- Fiction'...</td>\n",
       "      <td>Fiction</td>\n",
       "      <td>Love stories</td>\n",
       "      <td>Young women</td>\n",
       "      <td>Psychological fiction</td>\n",
       "      <td>2371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>PG105_2371</td>\n",
       "      <td>[-0.28961048, 0.38467273, 0.06806766, -0.14219...</td>\n",
       "      <td>5049.0</td>\n",
       "      <td>Austen, Jane</td>\n",
       "      <td>PG105</td>\n",
       "      <td>PG105</td>\n",
       "      <td>Persuasion</td>\n",
       "      <td>[Croft’s next words explained it to be Mr Went...</td>\n",
       "      <td>2371.0</td>\n",
       "      <td>1775.0</td>\n",
       "      <td>1817.0</td>\n",
       "      <td>2778.0</td>\n",
       "      <td>{'Regency fiction', 'Ship captains -- Fiction'...</td>\n",
       "      <td>Fiction</td>\n",
       "      <td>Love stories</td>\n",
       "      <td>Young women</td>\n",
       "      <td>Psychological fiction</td>\n",
       "      <td>2371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>PG105_2371</td>\n",
       "      <td>[-0.510949, 0.36323312, 0.12687655, -0.1873095...</td>\n",
       "      <td>5049.0</td>\n",
       "      <td>Austen, Jane</td>\n",
       "      <td>PG105</td>\n",
       "      <td>PG105</td>\n",
       "      <td>Persuasion</td>\n",
       "      <td>[Croft’s next words explained it to be Mr Went...</td>\n",
       "      <td>2371.0</td>\n",
       "      <td>1775.0</td>\n",
       "      <td>1817.0</td>\n",
       "      <td>2778.0</td>\n",
       "      <td>{'Regency fiction', 'Ship captains -- Fiction'...</td>\n",
       "      <td>Fiction</td>\n",
       "      <td>Love stories</td>\n",
       "      <td>Young women</td>\n",
       "      <td>Psychological fiction</td>\n",
       "      <td>2371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>PG105_2371</td>\n",
       "      <td>[-0.4631606, 0.34937078, 0.07573335, -0.178711...</td>\n",
       "      <td>5049.0</td>\n",
       "      <td>Austen, Jane</td>\n",
       "      <td>PG105</td>\n",
       "      <td>PG105</td>\n",
       "      <td>Persuasion</td>\n",
       "      <td>[Croft’s next words explained it to be Mr Went...</td>\n",
       "      <td>2371.0</td>\n",
       "      <td>1775.0</td>\n",
       "      <td>1817.0</td>\n",
       "      <td>2778.0</td>\n",
       "      <td>{'Regency fiction', 'Ship captains -- Fiction'...</td>\n",
       "      <td>Fiction</td>\n",
       "      <td>Love stories</td>\n",
       "      <td>Young women</td>\n",
       "      <td>Psychological fiction</td>\n",
       "      <td>2371</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   seqid passage_key                                    sent_embeddings  \\\n",
       "0      0  PG105_2371  [-0.40695864, 0.3818504, 0.060175154, -0.16981...   \n",
       "1      1  PG105_2371  [-0.33000952, 0.35164443, 0.05541102, -0.16663...   \n",
       "2      2  PG105_2371  [-0.28961048, 0.38467273, 0.06806766, -0.14219...   \n",
       "3      3  PG105_2371  [-0.510949, 0.36323312, 0.12687655, -0.1873095...   \n",
       "4      4  PG105_2371  [-0.4631606, 0.34937078, 0.07573335, -0.178711...   \n",
       "\n",
       "   author_id   author_name book_id gutenbergbookid       title  \\\n",
       "0     5049.0  Austen, Jane   PG105           PG105  Persuasion   \n",
       "1     5049.0  Austen, Jane   PG105           PG105  Persuasion   \n",
       "2     5049.0  Austen, Jane   PG105           PG105  Persuasion   \n",
       "3     5049.0  Austen, Jane   PG105           PG105  Persuasion   \n",
       "4     5049.0  Austen, Jane   PG105           PG105  Persuasion   \n",
       "\n",
       "                                                text  text_lines  \\\n",
       "0  [Croft’s next words explained it to be Mr Went...      2371.0   \n",
       "1  [Croft’s next words explained it to be Mr Went...      2371.0   \n",
       "2  [Croft’s next words explained it to be Mr Went...      2371.0   \n",
       "3  [Croft’s next words explained it to be Mr Went...      2371.0   \n",
       "4  [Croft’s next words explained it to be Mr Went...      2371.0   \n",
       "\n",
       "   authoryearofbirth  authoryearofdeath  downloads  \\\n",
       "0             1775.0             1817.0     2778.0   \n",
       "1             1775.0             1817.0     2778.0   \n",
       "2             1775.0             1817.0     2778.0   \n",
       "3             1775.0             1817.0     2778.0   \n",
       "4             1775.0             1817.0     2778.0   \n",
       "\n",
       "                                            subjects    topic         Sub_A  \\\n",
       "0  {'Regency fiction', 'Ship captains -- Fiction'...  Fiction  Love stories   \n",
       "1  {'Regency fiction', 'Ship captains -- Fiction'...  Fiction  Love stories   \n",
       "2  {'Regency fiction', 'Ship captains -- Fiction'...  Fiction  Love stories   \n",
       "3  {'Regency fiction', 'Ship captains -- Fiction'...  Fiction  Love stories   \n",
       "4  {'Regency fiction', 'Ship captains -- Fiction'...  Fiction  Love stories   \n",
       "\n",
       "         Sub_B                  Sub_C str_text_lines  \n",
       "0  Young women  Psychological fiction           2371  \n",
       "1  Young women  Psychological fiction           2371  \n",
       "2  Young women  Psychological fiction           2371  \n",
       "3  Young women  Psychological fiction           2371  \n",
       "4  Young women  Psychological fiction           2371  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embed_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a9caa6ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_df = embed_df.dropna(subset=['author_id', 'sent_embeddings'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "45bd8cb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "n_classes = embed_df.author_id.nunique()\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "# label_encoder=OneHotEncoder(sparse_output=False)\n",
    "# label_encoder=OneHotEncoder()\n",
    "label_encoder=LabelEncoder()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "802bee65",
   "metadata": {},
   "outputs": [],
   "source": [
    "y= label_encoder.fit_transform(embed_df['author_id']) #.to_numpy(dtype='int32').reshape(-1,1)\n",
    "# y = y.toarray()\n",
    "\n",
    "# y = embed_df['author_id'].astype('category')\n",
    "X = np.vstack(embed_df['sent_embeddings'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "427c2043",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.int64"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(y[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "33a2c9db",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "test_size = 0.2\n",
    "val_size = 0.2\n",
    "random_state =699\n",
    "\n",
    "X_train, X_test, y_train, y_test = U.train_test_split(X, y, test_size=test_size,\n",
    "                                                        random_state=random_state,\n",
    "                                                        stratify=y)\n",
    "\n",
    "# Split train set into train and validation sets\n",
    "X_train, X_val, y_train, y_val = U.train_test_split(X_train, y_train, test_size=val_size/(1-test_size),\n",
    "                                                    random_state=random_state,\n",
    "                                                    stratify=y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "329447e4",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb \n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "1cc9c7fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(441612, 100)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "9a929e81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['seqid', 'passage_key', 'sent_embeddings', 'author_id', 'author_name',\n",
       "       'book_id', 'gutenbergbookid', 'title', 'text', 'text_lines',\n",
       "       'authoryearofbirth', 'authoryearofdeath', 'downloads', 'subjects',\n",
       "       'topic', 'Sub_A', 'Sub_B', 'Sub_C', 'str_text_lines'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embed_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e6904bcf",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m rf_base \u001b[39m=\u001b[39m RandomForestClassifier(random_state\u001b[39m=\u001b[39;49m\u001b[39m699\u001b[39;49m)\u001b[39m.\u001b[39;49mfit(X_train, y_train)\n\u001b[1;32m      3\u001b[0m train_precision, train_recall, _ \u001b[39m=\u001b[39m (\n\u001b[1;32m      4\u001b[0m     U\u001b[39m.\u001b[39mprecision_recall_curve(y_train, rf_base\u001b[39m.\u001b[39mpredict_proba(X_train)[:, \u001b[39m1\u001b[39m])\n\u001b[1;32m      5\u001b[0m )\n\u001b[1;32m      6\u001b[0m val_precision, val_recall, _ \u001b[39m=\u001b[39m (\n\u001b[1;32m      7\u001b[0m     U\u001b[39m.\u001b[39mprecision_recall_curve(y_val, rf_base\u001b[39m.\u001b[39mpredict_proba(X_val)[:, \u001b[39m1\u001b[39m])\n\u001b[1;32m      8\u001b[0m )\n",
      "File \u001b[0;32m~/miniconda3/envs/si699proj/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:473\u001b[0m, in \u001b[0;36mBaseForest.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    462\u001b[0m trees \u001b[39m=\u001b[39m [\n\u001b[1;32m    463\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_make_estimator(append\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, random_state\u001b[39m=\u001b[39mrandom_state)\n\u001b[1;32m    464\u001b[0m     \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(n_more_estimators)\n\u001b[1;32m    465\u001b[0m ]\n\u001b[1;32m    467\u001b[0m \u001b[39m# Parallel loop: we prefer the threading backend as the Cython code\u001b[39;00m\n\u001b[1;32m    468\u001b[0m \u001b[39m# for fitting the trees is internally releasing the Python GIL\u001b[39;00m\n\u001b[1;32m    469\u001b[0m \u001b[39m# making threading more efficient than multiprocessing in\u001b[39;00m\n\u001b[1;32m    470\u001b[0m \u001b[39m# that case. However, for joblib 0.12+ we respect any\u001b[39;00m\n\u001b[1;32m    471\u001b[0m \u001b[39m# parallel_backend contexts set at a higher level,\u001b[39;00m\n\u001b[1;32m    472\u001b[0m \u001b[39m# since correctness does not rely on using threads.\u001b[39;00m\n\u001b[0;32m--> 473\u001b[0m trees \u001b[39m=\u001b[39m Parallel(\n\u001b[1;32m    474\u001b[0m     n_jobs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mn_jobs,\n\u001b[1;32m    475\u001b[0m     verbose\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mverbose,\n\u001b[1;32m    476\u001b[0m     prefer\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mthreads\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    477\u001b[0m )(\n\u001b[1;32m    478\u001b[0m     delayed(_parallel_build_trees)(\n\u001b[1;32m    479\u001b[0m         t,\n\u001b[1;32m    480\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbootstrap,\n\u001b[1;32m    481\u001b[0m         X,\n\u001b[1;32m    482\u001b[0m         y,\n\u001b[1;32m    483\u001b[0m         sample_weight,\n\u001b[1;32m    484\u001b[0m         i,\n\u001b[1;32m    485\u001b[0m         \u001b[39mlen\u001b[39;49m(trees),\n\u001b[1;32m    486\u001b[0m         verbose\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mverbose,\n\u001b[1;32m    487\u001b[0m         class_weight\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mclass_weight,\n\u001b[1;32m    488\u001b[0m         n_samples_bootstrap\u001b[39m=\u001b[39;49mn_samples_bootstrap,\n\u001b[1;32m    489\u001b[0m     )\n\u001b[1;32m    490\u001b[0m     \u001b[39mfor\u001b[39;49;00m i, t \u001b[39min\u001b[39;49;00m \u001b[39menumerate\u001b[39;49m(trees)\n\u001b[1;32m    491\u001b[0m )\n\u001b[1;32m    493\u001b[0m \u001b[39m# Collect newly grown trees\u001b[39;00m\n\u001b[1;32m    494\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mestimators_\u001b[39m.\u001b[39mextend(trees)\n",
      "File \u001b[0;32m~/miniconda3/envs/si699proj/lib/python3.9/site-packages/sklearn/utils/parallel.py:63\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     58\u001b[0m config \u001b[39m=\u001b[39m get_config()\n\u001b[1;32m     59\u001b[0m iterable_with_config \u001b[39m=\u001b[39m (\n\u001b[1;32m     60\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[1;32m     61\u001b[0m     \u001b[39mfor\u001b[39;00m delayed_func, args, kwargs \u001b[39min\u001b[39;00m iterable\n\u001b[1;32m     62\u001b[0m )\n\u001b[0;32m---> 63\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__call__\u001b[39;49m(iterable_with_config)\n",
      "File \u001b[0;32m~/miniconda3/envs/si699proj/lib/python3.9/site-packages/joblib/parallel.py:1088\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1085\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdispatch_one_batch(iterator):\n\u001b[1;32m   1086\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterating \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_original_iterator \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m-> 1088\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdispatch_one_batch(iterator):\n\u001b[1;32m   1089\u001b[0m     \u001b[39mpass\u001b[39;00m\n\u001b[1;32m   1091\u001b[0m \u001b[39mif\u001b[39;00m pre_dispatch \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mall\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mor\u001b[39;00m n_jobs \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m   1092\u001b[0m     \u001b[39m# The iterable was consumed all at once by the above for loop.\u001b[39;00m\n\u001b[1;32m   1093\u001b[0m     \u001b[39m# No need to wait for async callbacks to trigger to\u001b[39;00m\n\u001b[1;32m   1094\u001b[0m     \u001b[39m# consumption.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/si699proj/lib/python3.9/site-packages/joblib/parallel.py:901\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    899\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m    900\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 901\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dispatch(tasks)\n\u001b[1;32m    902\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/si699proj/lib/python3.9/site-packages/joblib/parallel.py:819\u001b[0m, in \u001b[0;36mParallel._dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    817\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[1;32m    818\u001b[0m     job_idx \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs)\n\u001b[0;32m--> 819\u001b[0m     job \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_backend\u001b[39m.\u001b[39;49mapply_async(batch, callback\u001b[39m=\u001b[39;49mcb)\n\u001b[1;32m    820\u001b[0m     \u001b[39m# A job can complete so quickly than its callback is\u001b[39;00m\n\u001b[1;32m    821\u001b[0m     \u001b[39m# called before we get here, causing self._jobs to\u001b[39;00m\n\u001b[1;32m    822\u001b[0m     \u001b[39m# grow. To ensure correct results ordering, .insert is\u001b[39;00m\n\u001b[1;32m    823\u001b[0m     \u001b[39m# used (rather than .append) in the following line\u001b[39;00m\n\u001b[1;32m    824\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs\u001b[39m.\u001b[39minsert(job_idx, job)\n",
      "File \u001b[0;32m~/miniconda3/envs/si699proj/lib/python3.9/site-packages/joblib/_parallel_backends.py:208\u001b[0m, in \u001b[0;36mSequentialBackend.apply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply_async\u001b[39m(\u001b[39mself\u001b[39m, func, callback\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m    207\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Schedule a func to be run\"\"\"\u001b[39;00m\n\u001b[0;32m--> 208\u001b[0m     result \u001b[39m=\u001b[39m ImmediateResult(func)\n\u001b[1;32m    209\u001b[0m     \u001b[39mif\u001b[39;00m callback:\n\u001b[1;32m    210\u001b[0m         callback(result)\n",
      "File \u001b[0;32m~/miniconda3/envs/si699proj/lib/python3.9/site-packages/joblib/_parallel_backends.py:597\u001b[0m, in \u001b[0;36mImmediateResult.__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    594\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, batch):\n\u001b[1;32m    595\u001b[0m     \u001b[39m# Don't delay the application, to avoid keeping the input\u001b[39;00m\n\u001b[1;32m    596\u001b[0m     \u001b[39m# arguments in memory\u001b[39;00m\n\u001b[0;32m--> 597\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mresults \u001b[39m=\u001b[39m batch()\n",
      "File \u001b[0;32m~/miniconda3/envs/si699proj/lib/python3.9/site-packages/joblib/parallel.py:288\u001b[0m, in \u001b[0;36mBatchedCalls.__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    285\u001b[0m     \u001b[39m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[1;32m    286\u001b[0m     \u001b[39m# change the default number of processes to -1\u001b[39;00m\n\u001b[1;32m    287\u001b[0m     \u001b[39mwith\u001b[39;00m parallel_backend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, n_jobs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_jobs):\n\u001b[0;32m--> 288\u001b[0m         \u001b[39mreturn\u001b[39;00m [func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    289\u001b[0m                 \u001b[39mfor\u001b[39;00m func, args, kwargs \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitems]\n",
      "File \u001b[0;32m~/miniconda3/envs/si699proj/lib/python3.9/site-packages/joblib/parallel.py:288\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    285\u001b[0m     \u001b[39m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[1;32m    286\u001b[0m     \u001b[39m# change the default number of processes to -1\u001b[39;00m\n\u001b[1;32m    287\u001b[0m     \u001b[39mwith\u001b[39;00m parallel_backend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, n_jobs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_jobs):\n\u001b[0;32m--> 288\u001b[0m         \u001b[39mreturn\u001b[39;00m [func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    289\u001b[0m                 \u001b[39mfor\u001b[39;00m func, args, kwargs \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitems]\n",
      "File \u001b[0;32m~/miniconda3/envs/si699proj/lib/python3.9/site-packages/sklearn/utils/parallel.py:123\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    121\u001b[0m     config \u001b[39m=\u001b[39m {}\n\u001b[1;32m    122\u001b[0m \u001b[39mwith\u001b[39;00m config_context(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mconfig):\n\u001b[0;32m--> 123\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfunction(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/si699proj/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:184\u001b[0m, in \u001b[0;36m_parallel_build_trees\u001b[0;34m(tree, bootstrap, X, y, sample_weight, tree_idx, n_trees, verbose, class_weight, n_samples_bootstrap)\u001b[0m\n\u001b[1;32m    181\u001b[0m     \u001b[39melif\u001b[39;00m class_weight \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mbalanced_subsample\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m    182\u001b[0m         curr_sample_weight \u001b[39m*\u001b[39m\u001b[39m=\u001b[39m compute_sample_weight(\u001b[39m\"\u001b[39m\u001b[39mbalanced\u001b[39m\u001b[39m\"\u001b[39m, y, indices\u001b[39m=\u001b[39mindices)\n\u001b[0;32m--> 184\u001b[0m     tree\u001b[39m.\u001b[39;49mfit(X, y, sample_weight\u001b[39m=\u001b[39;49mcurr_sample_weight, check_input\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[1;32m    185\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    186\u001b[0m     tree\u001b[39m.\u001b[39mfit(X, y, sample_weight\u001b[39m=\u001b[39msample_weight, check_input\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m~/miniconda3/envs/si699proj/lib/python3.9/site-packages/sklearn/tree/_classes.py:889\u001b[0m, in \u001b[0;36mDecisionTreeClassifier.fit\u001b[0;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[1;32m    859\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfit\u001b[39m(\u001b[39mself\u001b[39m, X, y, sample_weight\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, check_input\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m):\n\u001b[1;32m    860\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Build a decision tree classifier from the training set (X, y).\u001b[39;00m\n\u001b[1;32m    861\u001b[0m \n\u001b[1;32m    862\u001b[0m \u001b[39m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    886\u001b[0m \u001b[39m        Fitted estimator.\u001b[39;00m\n\u001b[1;32m    887\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 889\u001b[0m     \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mfit(\n\u001b[1;32m    890\u001b[0m         X,\n\u001b[1;32m    891\u001b[0m         y,\n\u001b[1;32m    892\u001b[0m         sample_weight\u001b[39m=\u001b[39;49msample_weight,\n\u001b[1;32m    893\u001b[0m         check_input\u001b[39m=\u001b[39;49mcheck_input,\n\u001b[1;32m    894\u001b[0m     )\n\u001b[1;32m    895\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "File \u001b[0;32m~/miniconda3/envs/si699proj/lib/python3.9/site-packages/sklearn/tree/_classes.py:379\u001b[0m, in \u001b[0;36mBaseDecisionTree.fit\u001b[0;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[1;32m    368\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    369\u001b[0m     builder \u001b[39m=\u001b[39m BestFirstTreeBuilder(\n\u001b[1;32m    370\u001b[0m         splitter,\n\u001b[1;32m    371\u001b[0m         min_samples_split,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    376\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmin_impurity_decrease,\n\u001b[1;32m    377\u001b[0m     )\n\u001b[0;32m--> 379\u001b[0m builder\u001b[39m.\u001b[39;49mbuild(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtree_, X, y, sample_weight)\n\u001b[1;32m    381\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_outputs_ \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m \u001b[39mand\u001b[39;00m is_classifier(\u001b[39mself\u001b[39m):\n\u001b[1;32m    382\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_classes_ \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_classes_[\u001b[39m0\u001b[39m]\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "rf_base = RandomForestClassifier(random_state=699).fit(X_train, y_train)\n",
    "\n",
    "train_precision, train_recall, _ = (\n",
    "    U.precision_recall_curve(y_train, rf_base.predict_proba(X_train)[:, 1])\n",
    ")\n",
    "val_precision, val_recall, _ = (\n",
    "    U.precision_recall_curve(y_val, rf_base.predict_proba(X_val)[:, 1])\n",
    ")\n",
    "\n",
    "train_auprc = U.auc(train_recall, train_precision)\n",
    "val_auprc = U.auc(val_recall, val_precision)\n",
    "\n",
    "print(round(train_auprc, 3))\n",
    "print(round(val_auprc, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e38400d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cpu'\n",
    "# device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "# device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "kwargs = {'num_workers': 1, 'pin_memory': True} if (device == \"cuda:0\" or device == 'mps') else {}\n",
    "collate_func = lambda x: tuple(x_.to(device) for x_ in default_collate(x)) if device != \"cpu\" else default_collate(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e1083713",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = make_pipeline(StandardScaler(), SVC(gamma='auto'))\n",
    "clf.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47809fdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DocumentAttentionClassifier(nn.Module):\n",
    "    \n",
    "    def __init__(self, vocab_size, embedding_size, num_heads, hidden_dim, embeddings_fname, n_classes):\n",
    "        '''\n",
    "        Creates the new classifier model. embeddings_fname is a string containing the\n",
    "        filename with the saved pytorch parameters (the state dict) for the Embedding\n",
    "        object that should be used to initialize this class's word Embedding parameters\n",
    "        '''\n",
    "        super(DocumentAttentionClassifier, self).__init__()\n",
    "        \n",
    "        # Save the input arguments to the state\n",
    "        self.vocab_size = vocab_size\n",
    "        self.embedding_size = embedding_size\n",
    "        self.num_heads = num_heads\n",
    "        self.embeddings_fname = vocab_size        \n",
    "\n",
    "        self.linear = nn.Linear(num_heads * embedding_size, n_classes)\n",
    "        self.lstm = nn.LSTM(embedding_size, hidden_dim, batch_first=True, bidirectional=True)\n",
    "        self.attention = torch.rand(self.num_heads, hidden_dim * 2, requires_grad = True, device=device)\n",
    "        # self.attention = torch.rand(self.num_heads, self.embedding_size, requires_grad = True, device=device)\n",
    "        \n",
    "    def forward(self, w):\n",
    "        w = w.squeeze(1)\n",
    "        # w = torch.t(self.embeddings(word_ids).squeeze()) # Embedding_Dim \n",
    "        lstm_out, _ = self.lstm(w.T)\n",
    "        r = torch.matmul(self.attention, lstm_out.T)\n",
    "        a = torch.softmax(r, -1)\n",
    "        reweighted = a @ w\n",
    "        output = self.linear(reweighted.view(-1))\n",
    "\n",
    "        return torch.softmax(output, dim=0), a.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "155ce116",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = {}\n",
    "\n",
    "datasets['train'] = list(zip(X_train, y_train))\n",
    "datasets['val'] = list(zip(X_val, y_val))\n",
    "datasets['test'] = list(zip(X_test, y_test))\n",
    "\n",
    "train_list = datasets['train']\n",
    "val_list = datasets['val']\n",
    "test_list = datasets['test']\n",
    "\n",
    "model = DocumentAttentionClassifier(1, 100, 4, 32, 'trained_model_final', n_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4c0b4e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_eval(model, eval_data, kwargs):\n",
    "    '''\n",
    "    Scores the model on the evaluation data and returns the F1\n",
    "    Eval Data must be in DataLoader-ready format\n",
    "    '''\n",
    "\n",
    "    eval_loader = DataLoader(eval_data, batch_size = 1, shuffle = False, collate_fn=collate_func, **kwargs)\n",
    "\n",
    "    threshold = 0.2\n",
    "    probs  = np.zeros((len(eval_loader), n_classes))\n",
    "    labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for idx, x in enumerate(eval_loader):\n",
    "            word_ids, label = x\n",
    "            labels.append(label.cpu().numpy())\n",
    "            word_ids = word_ids.unsqueeze(1)\n",
    "            output, weights = model(word_ids)\n",
    "            probs[idx] = output.cpu().numpy()\n",
    "    \n",
    "    \n",
    "    y_pred = np.argmax(probs, 1)\n",
    "    labels = np.array(labels).squeeze().argmax(1)\n",
    "    \n",
    "    return labels, y_pred, f1_score(labels, y_pred, average='weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4cac31a",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "loss_period = 5\n",
    "# model = model.to(device)\n",
    "writer = SummaryWriter()\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "\n",
    "# VVV GOLD STANDARD VVV\n",
    "optimizer = optim.AdamW(model.parameters(), lr = 5e-3, weight_decay = 0.1)\n",
    "# ^^^ GOLD STANDARD ^^^\n",
    "\n",
    "# optimizer = optim.AdamW(model.parameters(), lr = 5e-3, weight_decay = 0.001)\n",
    "\n",
    "# optimizer = optim.AdamW(model.parameters())\n",
    "# optimizer = optim.RMSprop(model.parameters(), 5e-3)\n",
    "# optimizer = optim.SGD(model.parameters(), lr = 5e-4)\n",
    "\n",
    "train_loader = DataLoader(train_list, batch_size=16, shuffle=True, collate_fn=collate_func, **kwargs)\n",
    "n_epochs = 10\n",
    "n_epochs = 1\n",
    "\n",
    "# + vscode={\"languageId\": \"python\"}\n",
    "loss_idx = 0\n",
    "loss_record = []\n",
    "model.train()\n",
    "\n",
    "# + vscode={\"languageId\": \"python\"}r\n",
    "for epoch in tqdm(range(n_epochs)):\n",
    "\n",
    "    loss_sum = 0\n",
    "\n",
    "    for step, data in tqdm(enumerate(train_loader)):\n",
    "\n",
    "        word_ids, labels = data\n",
    "        labels = labels.argmax()\n",
    "        model.train()\n",
    "        model.zero_grad()\n",
    "        output, weights = model(word_ids)\n",
    "        loss = loss_function(output, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        loss_sum += loss.item()\n",
    "        \n",
    "        # TODO: Based on the details in the Homework PDF, periodically\n",
    "        # report the running-sum of the loss to tensorboard. Be sure\n",
    "        # to reset the running sum after reporting it.\n",
    "\n",
    "        if not step % loss_period and step:\n",
    "            writer.add_scalar(\"Loss\", loss_sum, loss_idx)\n",
    "            # if not step % (loss_period * 10) and step:\n",
    "            #     model.eval()\n",
    "            #     _y, _y2, f1 = run_eval(model, dev_list, kwargs)\n",
    "            #     writer.add_scalar(\"F1\", f1, loss_idx)\n",
    "            #     model.train()\n",
    "            loss_record.append(loss_sum)\n",
    "            loss_sum = 0\n",
    "            loss_idx += 1\n",
    "            \n",
    "\n",
    "        # TODO: it can be helpful to add some early stopping here after\n",
    "        # a fixed number of steps (e.g., if step > max_steps)\n",
    "        \n",
    "\n",
    "# once you finish training, it's good practice to switch to eval.\n",
    "model.eval()\n",
    "\n",
    "y_true, y_pred, f1 = run_eval(model, val_list, kwargs)\n",
    "print(\"Eval F1 Score of : \"+ str(f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d74d51cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true, y_pred, f1 = run_eval(model, test_list, kwargs)\n",
    "print(\"Test F1 Score of : \"+ str(f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c73af21d",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(optimizer.state_dict(), 'trained_opt_' + suffix)\n",
    "torch.save(model.state_dict(), 'trained_model_' + suffix)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "si699proj",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
