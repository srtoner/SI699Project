{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "4e765841",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle as pkl\n",
    "import seaborn as sns\n",
    "import gensim\n",
    "from gensim.test.utils import common_texts\n",
    "import torch\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "# load config\n",
    "with open('config.json', 'r') as f:\n",
    "    config = json.load(f)\n",
    "cwd = os.getcwd()\n",
    "os.chdir(config['REPODIR'])\n",
    "import Utils as U\n",
    "from Corpus import Corpus\n",
    "os.chdir(cwd)\n",
    "\n",
    "from collections import Counter, defaultdict\n",
    "import itertools\n",
    "\n",
    "\n",
    "from tqdm.auto import tqdm, trange\n",
    "from collections import Counter\n",
    "import random\n",
    "from torch import optim\n",
    "from gensim.models import KeyedVectors\n",
    "from gensim.test.utils import datapath\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "sns.set_theme(style=\"dark\")\n",
    "import pickle as pkl\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import f1_score\n",
    "import nltk\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data.dataloader import default_collate\n",
    "\n",
    "torch.set_default_dtype(torch.float32)\n",
    "\n",
    "from torch.utils.data.dataloader import default_collate\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import torch\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "# device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "kwargs = {'num_workers': 4, 'pin_memory': True} \\\n",
    "         if (device == \"cuda:0\" or device == 'mps') else {}\n",
    "collate_func = lambda x: tuple(x_.to(device) for x_ in default_collate(x)) \\\n",
    "               if device != \"cpu\" else default_collate\n",
    "\n",
    "# with open('embedding_data.pkl', 'rb') as f:\n",
    "#     embed = pkl.load(f)\n",
    "\n",
    "# embed_df = pd.DataFrame(embed)\n",
    "\n",
    "\n",
    "# n_classes = embed_df.author_id.nunique()\n",
    "\n",
    "# from sklearn.preprocessing import OneHotEncoder\n",
    "# label_encoder=OneHotEncoder(sparse_output=False)\n",
    "\n",
    "# # -\n",
    "\n",
    "\n",
    "# X = embed_df['vectors'] # Word Embeddings\n",
    "\n",
    "# +\n",
    "test_size = 0.2\n",
    "val_size = 0.2\n",
    "random_state =699\n",
    "\n",
    "\n",
    "# +\n",
    "with open('sentence_embed.pkl', 'rb') as f:\n",
    "    embed = pkl.load(f)\n",
    "\n",
    "embed_df = pd.DataFrame(embed)\n",
    "\n",
    "data = U.load_file('data_vFFFF.pkl', 'pkl', config['DATADIR'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "c80a397c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embed_df[2][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "541bab79",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "fdf976b9",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "embed_df = pd.DataFrame(data)\n",
    "\n",
    "embed_df['join_text'] = embed_df['text'].apply(' '.join)\n",
    "embed_df = embed_df[['author_id', 'text', 'join_text', 'passage_key']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6cafd0f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "68b442da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ec93475",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "df392624",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/srtoner/.local/lib/python3.9/site-packages/sklearn/preprocessing/_label.py:115: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "n_classes = embed_df.author_id.nunique()\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "label_encoder=LabelEncoder()\n",
    "y= label_encoder.fit_transform(embed_df['author_id'].to_numpy(dtype='int32').reshape(-1,1))\n",
    "X = embed_df['passage_key']\n",
    "\n",
    "X_train, X_test, y_train, y_test = U.train_test_split(X, y, test_size=test_size,\n",
    "                                                        random_state=random_state,\n",
    "                                                        stratify=y)\n",
    "\n",
    "# Split train set into train and validation sets\n",
    "X_train, X_val, y_train, y_val = U.train_test_split(X_train, y_train, test_size=val_size/(1-test_size),\n",
    "                                                    random_state=random_state,\n",
    "                                                    stratify=y_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "d3efdc7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_df['label'] = y\n",
    "\n",
    "train_set = set(X_train)\n",
    "val_set = set(X_val)\n",
    "test_set = set(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "16952596",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = embed_df[embed_df['passage_key'].apply(lambda S: S in train_set)]\n",
    "val = embed_df[embed_df['passage_key'].apply(lambda S: S in val_set)]\n",
    "test = embed_df[embed_df['passage_key'].apply(lambda S: S in test_set)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "1e29b666",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.to_csv('train.csv', index=False)\n",
    "val.to_csv('val.csv', index=False)\n",
    "test.to_csv('test.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "25ee852c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author_id</th>\n",
       "      <th>text</th>\n",
       "      <th>join_text</th>\n",
       "      <th>passage_key</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2210</td>\n",
       "      <td>[“No.”, , “I will buy it of you.”, , “No.”, , ...</td>\n",
       "      <td>“No.”  “I will buy it of you.”  “No.”  Phileas...</td>\n",
       "      <td>PG103_7736</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2210</td>\n",
       "      <td>[Bombay, for which they were now detained at C...</td>\n",
       "      <td>Bombay, for which they were now detained at Ca...</td>\n",
       "      <td>PG103_3686</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2210</td>\n",
       "      <td>[, “Well, Monsieur Fix,” said Passepartout, “h...</td>\n",
       "      <td>“Well, Monsieur Fix,” said Passepartout, “hav...</td>\n",
       "      <td>PG103_4386</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2210</td>\n",
       "      <td>[but the intractable Fogg, as reserved as ever...</td>\n",
       "      <td>but the intractable Fogg, as reserved as ever,...</td>\n",
       "      <td>PG103_3836</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2210</td>\n",
       "      <td>[“I am he.”, , “Is this man your servant?” add...</td>\n",
       "      <td>“I am he.”  “Is this man your servant?” added ...</td>\n",
       "      <td>PG103_3536</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27780</th>\n",
       "      <td>1306</td>\n",
       "      <td>[    \"He was our playmate; us he understood,  ...</td>\n",
       "      <td>\"He was our playmate; us he understood    ...</td>\n",
       "      <td>PG47265_447</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27781</th>\n",
       "      <td>1306</td>\n",
       "      <td>[, , *THE SANDHILLS*, , ,     Oh, naked-footed...</td>\n",
       "      <td>*THE SANDHILLS*       Oh, naked-footed boy, ...</td>\n",
       "      <td>PG47265_397</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27783</th>\n",
       "      <td>1306</td>\n",
       "      <td>[*SCANDAL*, , ,     An owl alighted in the yew...</td>\n",
       "      <td>*SCANDAL*       An owl alighted in the yew    ...</td>\n",
       "      <td>PG47265_797</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27784</th>\n",
       "      <td>1306</td>\n",
       "      <td>[    And by the lattice climbs a crimson rose,...</td>\n",
       "      <td>And by the lattice climbs a crimson rose, ...</td>\n",
       "      <td>PG47265_997</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27785</th>\n",
       "      <td>1306</td>\n",
       "      <td>[      While morning leaps the hither hill,   ...</td>\n",
       "      <td>While morning leaps the hither hill     ...</td>\n",
       "      <td>PG47265_947</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16671 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       author_id                                               text  \\\n",
       "0           2210  [“No.”, , “I will buy it of you.”, , “No.”, , ...   \n",
       "1           2210  [Bombay, for which they were now detained at C...   \n",
       "2           2210  [, “Well, Monsieur Fix,” said Passepartout, “h...   \n",
       "3           2210  [but the intractable Fogg, as reserved as ever...   \n",
       "4           2210  [“I am he.”, , “Is this man your servant?” add...   \n",
       "...          ...                                                ...   \n",
       "27780       1306  [    \"He was our playmate; us he understood,  ...   \n",
       "27781       1306  [, , *THE SANDHILLS*, , ,     Oh, naked-footed...   \n",
       "27783       1306  [*SCANDAL*, , ,     An owl alighted in the yew...   \n",
       "27784       1306  [    And by the lattice climbs a crimson rose,...   \n",
       "27785       1306  [      While morning leaps the hither hill,   ...   \n",
       "\n",
       "                                               join_text  passage_key  label  \n",
       "0      “No.”  “I will buy it of you.”  “No.”  Phileas...   PG103_7736     18  \n",
       "1      Bombay, for which they were now detained at Ca...   PG103_3686     18  \n",
       "2       “Well, Monsieur Fix,” said Passepartout, “hav...   PG103_4386     18  \n",
       "3      but the intractable Fogg, as reserved as ever,...   PG103_3836     18  \n",
       "4      “I am he.”  “Is this man your servant?” added ...   PG103_3536     18  \n",
       "...                                                  ...          ...    ...  \n",
       "27780      \"He was our playmate; us he understood    ...  PG47265_447     12  \n",
       "27781    *THE SANDHILLS*       Oh, naked-footed boy, ...  PG47265_397     12  \n",
       "27783  *SCANDAL*       An owl alighted in the yew    ...  PG47265_797     12  \n",
       "27784      And by the lattice climbs a crimson rose, ...  PG47265_997     12  \n",
       "27785        While morning leaps the hither hill     ...  PG47265_947     12  \n",
       "\n",
       "[16671 rows x 5 columns]"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "daed2309",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "74003731",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset csv/default to /home/srtoner/.cache/huggingface/datasets/csv/default-2d49eeb56c047ef0/0.0.0...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7058458614648df858f1616426c499f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5334dfc5236c475c9bf1420d0b3fae43",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset csv downloaded and prepared to /home/srtoner/.cache/huggingface/datasets/csv/default-2d49eeb56c047ef0/0.0.0. Subsequent calls will reuse this data.\n",
      "Downloading and preparing dataset csv/default to /home/srtoner/.cache/huggingface/datasets/csv/default-2847c6b0d9638046/0.0.0...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "68f6ea974fdd4f88b51f3eb1b55a43d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f66328d7ba16488c9b3fc24816215776",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset csv downloaded and prepared to /home/srtoner/.cache/huggingface/datasets/csv/default-2847c6b0d9638046/0.0.0. Subsequent calls will reuse this data.\n",
      "Downloading and preparing dataset csv/default to /home/srtoner/.cache/huggingface/datasets/csv/default-e7504e7417ecc489/0.0.0...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3754389e38514b53be028a2eaf3a62af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "80a6ffd84b14445fa9f3a454d4f76107",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset csv downloaded and prepared to /home/srtoner/.cache/huggingface/datasets/csv/default-e7504e7417ecc489/0.0.0. Subsequent calls will reuse this data.\n"
     ]
    }
   ],
   "source": [
    "ds = {\n",
    "      'train' :  Dataset.from_csv('train.csv'),\n",
    "      'val' :  Dataset.from_csv('val.csv'),\n",
    "      'test' :  Dataset.from_csv('test.csv'),\n",
    "      }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "49c98c8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['author_id', 'text', 'join_text', 'passage_key', 'label'], dtype='object')"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embed_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "77af4a2a",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at microsoft/MiniLM-L12-H384-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, DataCollatorWithPadding\n",
    "from transformers.integrations import TensorBoardCallback\n",
    "from transformers.trainer_callback import EarlyStoppingCallback\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "ds1 = {}\n",
    "\n",
    "BASE_MODEL = \"microsoft/MiniLM-L12-H384-uncased\"\n",
    "# BASE_MODEL = \"allenai/longformer-base-4096\"\n",
    "# BASE_MODEL = \"lreN5bs16\" # Learning Rate 2e-5, batch size 16\n",
    "LEARNING_RATE = 2e-5\n",
    "MAX_LENGTH = 510\n",
    "BATCH_SIZE = 16\n",
    "EPOCHS = 20\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(BASE_MODEL)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(BASE_MODEL, \n",
    "                                                           num_labels=n_classes,\n",
    "                                                           ignore_mismatched_sizes=True)\n",
    "\n",
    "def preprocess_function(examples, test = False):\n",
    "    # if not test:\n",
    "    label = examples[\"label\"] \n",
    "    examples = tokenizer(examples[\"join_text\"],\n",
    "                        truncation=True, \n",
    "                        padding=\"max_length\",\n",
    "                        max_length=MAX_LENGTH,\n",
    "                        return_tensors='pt')\n",
    "    \n",
    "    for key in examples:\n",
    "        examples[key] = examples[key].squeeze(0)\n",
    "  \n",
    "    # if not test:\n",
    "    examples[\"label\"] = torch.IntTensor([label])\n",
    "    examples = examples.to(device)\n",
    "    return examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "109e1b1b",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/16671 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/5558 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/5558 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for split in ds:\n",
    "    ds1[split] = ds[split].map(preprocess_function, \n",
    "                                remove_columns=['author_id', 'text', 'passage_key','join_text', 'label'])\n",
    "\n",
    "    ds1[split].set_format('pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "e259538b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments, Trainer\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"output/\",\n",
    "    learning_rate=LEARNING_RATE,\n",
    "    per_device_train_batch_size=BATCH_SIZE,\n",
    "    per_device_eval_batch_size=BATCH_SIZE,\n",
    "    logging_steps = 1,\n",
    "    num_train_epochs=EPOCHS,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    metric_for_best_model=\"F1\",\n",
    "    greater_is_better=True,\n",
    "    load_best_model_at_end=True,\n",
    "    weight_decay=0.01,\n",
    "    report_to = 'tensorboard'\n",
    ")\n",
    "\n",
    "early_stop = EarlyStoppingCallback(1, 0.01)\n",
    "tb = TensorBoardCallback()\n",
    "\n",
    "\n",
    "from transformers import Trainer\n",
    "class CustomTrainer(Trainer):\n",
    "    def compute_loss(self, model, inputs, return_outputs=False):\n",
    "        labels = inputs.get(\"labels\")\n",
    "        outputs = model(**inputs)\n",
    "        logits = outputs.get(\"logits\")\n",
    "\n",
    "        loss_fct = nn.functional.cross_entropy\n",
    "        loss = loss_fct(logits.view(-1, n_classes), labels.view(-1))\n",
    "        return (loss, outputs) if return_outputs else loss\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "f54be5ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score as f1s\n",
    "\n",
    "def compute_metrics_for_classification(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    labels = labels.reshape(-1, 1)\n",
    "    print(labels)\n",
    "    print(type(predictions))\n",
    "    \n",
    "    predicted_class = predictions.argmax(axis=1)\n",
    "    print(predicted_class)\n",
    "    f1 = f1s(labels, predicted_class,average = 'weighted')\n",
    "    print(f\"F1: {f1}\")\n",
    "    \n",
    "    return {\"F1\": f1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "774f2172",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = CustomTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=ds1[\"train\"],\n",
    "    eval_dataset=ds1[\"val\"],\n",
    "    compute_metrics=compute_metrics_for_classification,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32adff86",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/srtoner/.local/lib/python3.9/site-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='8624' max='20840' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 8624/20840 37:19 < 52:53, 3.85 it/s, Epoch 8.28/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.006500</td>\n",
       "      <td>2.639907</td>\n",
       "      <td>0.301173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2.540000</td>\n",
       "      <td>2.156227</td>\n",
       "      <td>0.360174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.561000</td>\n",
       "      <td>1.832863</td>\n",
       "      <td>0.457310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.539200</td>\n",
       "      <td>1.512801</td>\n",
       "      <td>0.579973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.250000</td>\n",
       "      <td>1.332440</td>\n",
       "      <td>0.628858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>1.351800</td>\n",
       "      <td>1.196575</td>\n",
       "      <td>0.662417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.401200</td>\n",
       "      <td>1.034151</td>\n",
       "      <td>0.704973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.701600</td>\n",
       "      <td>0.973756</td>\n",
       "      <td>0.712966</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[18]\n",
      " [18]\n",
      " [18]\n",
      " ...\n",
      " [12]\n",
      " [12]\n",
      " [12]]\n",
      "<class 'numpy.ndarray'>\n",
      "[17 17 17 ...  1  1 27]\n",
      "F1: 0.3011732932745492\n",
      "[[18]\n",
      " [18]\n",
      " [18]\n",
      " ...\n",
      " [12]\n",
      " [12]\n",
      " [12]]\n",
      "<class 'numpy.ndarray'>\n",
      "[ 4 17 17 ...  1  1  1]\n",
      "F1: 0.36017410132429845\n",
      "[[18]\n",
      " [18]\n",
      " [18]\n",
      " ...\n",
      " [12]\n",
      " [12]\n",
      " [12]]\n",
      "<class 'numpy.ndarray'>\n",
      "[ 4 18 18 ... 15 27 27]\n",
      "F1: 0.45730994628148447\n",
      "[[18]\n",
      " [18]\n",
      " [18]\n",
      " ...\n",
      " [12]\n",
      " [12]\n",
      " [12]]\n",
      "<class 'numpy.ndarray'>\n",
      "[18 18 18 ... 15 27  6]\n",
      "F1: 0.5799726447943793\n",
      "[[18]\n",
      " [18]\n",
      " [18]\n",
      " ...\n",
      " [12]\n",
      " [12]\n",
      " [12]]\n",
      "<class 'numpy.ndarray'>\n",
      "[18 18 18 ... 50 51 51]\n",
      "F1: 0.6288581267231885\n",
      "[[18]\n",
      " [18]\n",
      " [18]\n",
      " ...\n",
      " [12]\n",
      " [12]\n",
      " [12]]\n",
      "<class 'numpy.ndarray'>\n",
      "[18 18 18 ... 50 30 10]\n",
      "F1: 0.6624167732544448\n",
      "[[18]\n",
      " [18]\n",
      " [18]\n",
      " ...\n",
      " [12]\n",
      " [12]\n",
      " [12]]\n",
      "<class 'numpy.ndarray'>\n",
      "[18 18 18 ... 48 10 41]\n",
      "F1: 0.7049730550835361\n",
      "[[18]\n",
      " [18]\n",
      " [18]\n",
      " ...\n",
      " [12]\n",
      " [12]\n",
      " [12]]\n",
      "<class 'numpy.ndarray'>\n",
      "[18 18 18 ... 48 10 49]\n",
      "F1: 0.7129659038883883\n"
     ]
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "0eb49e32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='348' max='348' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [348/348 00:25]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[18]\n",
      " [18]\n",
      " [18]\n",
      " ...\n",
      " [12]\n",
      " [12]\n",
      " [12]]\n",
      "<class 'numpy.ndarray'>\n",
      "[18 18 18 ... 49 49 48]\n",
      "F1: 0.7140582871448018\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 1.0358072519302368,\n",
       " 'eval_F1': 0.7140582871448018,\n",
       " 'eval_runtime': 25.1177,\n",
       " 'eval_samples_per_second': 221.278,\n",
       " 'eval_steps_per_second': 13.855,\n",
       " 'epoch': 10.0}"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "a763af7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "56"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_classes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "051ae507",
   "metadata": {},
   "source": [
    "prediction = trainer.predict(ds['validation'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "efeb66ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_model('hf_model_2')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
