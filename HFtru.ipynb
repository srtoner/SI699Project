{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a06926fb",
   "metadata": {
    "endofcell": "--"
   },
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle as pkl\n",
    "import seaborn as sns\n",
    "import gensim\n",
    "from gensim.test.utils import common_texts\n",
    "import torch\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "# load config\n",
    "with open('config.json', 'r') as f:\n",
    "    config = json.load(f)\n",
    "cwd = os.getcwd()\n",
    "os.chdir(config['REPODIR'])\n",
    "import Utils as U\n",
    "from Corpus import Corpus\n",
    "os.chdir(cwd)\n",
    "\n",
    "from collections import Counter, defaultdict\n",
    "import itertools\n",
    "\n",
    "\n",
    "from tqdm.auto import tqdm, trange\n",
    "from collections import Counter\n",
    "import random\n",
    "from torch import optim\n",
    "from gensim.models import KeyedVectors\n",
    "from gensim.test.utils import datapath\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "sns.set_theme(style=\"dark\")\n",
    "import pickle as pkl\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import f1_score\n",
    "import nltk\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data.dataloader import default_collate\n",
    "\n",
    "torch.set_default_dtype(torch.float32)\n",
    "\n",
    "from torch.utils.data.dataloader import default_collate\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import torch\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "# device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "kwargs = {'num_workers': 4, 'pin_memory': True} \\\n",
    "         if (device == \"cuda:0\" or device == 'mps') else {}\n",
    "collate_func = lambda x: tuple(x_.to(device) for x_ in default_collate(x)) \\\n",
    "               if device != \"cpu\" else default_collate\n",
    "\n",
    "# +\n",
    "test_size = 0.2\n",
    "val_size = 0.2\n",
    "random_state =699\n",
    "suffix = \"tiny\"\n",
    "\n",
    "# +\n",
    "with open('embedding_data_final.pkl', 'rb') as f:\n",
    "    embed = pkl.load(f)\n",
    "\n",
    "embed_df = pd.DataFrame(embed)\n",
    "\n",
    "data = U.load_file(f'data_vF_{suffix}.pkl', 'pkl', config['DATADIR'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c80a397c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author_id</th>\n",
       "      <th>text</th>\n",
       "      <th>join_text</th>\n",
       "      <th>passage_key</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1082</td>\n",
       "      <td>[This silence for my sin you did impute,, Whic...</td>\n",
       "      <td>This silence for my sin you did impute, Which ...</td>\n",
       "      <td>PG1041_1675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1082</td>\n",
       "      <td>[Sland’ring creation with a false esteem:,    ...</td>\n",
       "      <td>Sland’ring creation with a false esteem:     Y...</td>\n",
       "      <td>PG1041_2425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1082</td>\n",
       "      <td>[To me, fair friend, you never can be old,, Fo...</td>\n",
       "      <td>To me, fair friend, you never can be old, For ...</td>\n",
       "      <td>PG1041_2025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1082</td>\n",
       "      <td>[From hands of falsehood, in sure wards of tru...</td>\n",
       "      <td>From hands of falsehood, in sure wards of trus...</td>\n",
       "      <td>PG1041_1075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1082</td>\n",
       "      <td>[    To show false Art what beauty was of yore...</td>\n",
       "      <td>To show false Art what beauty was of yore....</td>\n",
       "      <td>PG1041_1425</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   author_id                                               text  \\\n",
       "0       1082  [This silence for my sin you did impute,, Whic...   \n",
       "1       1082  [Sland’ring creation with a false esteem:,    ...   \n",
       "2       1082  [To me, fair friend, you never can be old,, Fo...   \n",
       "3       1082  [From hands of falsehood, in sure wards of tru...   \n",
       "4       1082  [    To show false Art what beauty was of yore...   \n",
       "\n",
       "                                           join_text  passage_key  \n",
       "0  This silence for my sin you did impute, Which ...  PG1041_1675  \n",
       "1  Sland’ring creation with a false esteem:     Y...  PG1041_2425  \n",
       "2  To me, fair friend, you never can be old, For ...  PG1041_2025  \n",
       "3  From hands of falsehood, in sure wards of trus...  PG1041_1075  \n",
       "4      To show false Art what beauty was of yore....  PG1041_1425  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embed_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "58f340de",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "embed_df = pd.DataFrame(data)\n",
    "\n",
    "embed_df['join_text'] = embed_df['text'].apply(' '.join)\n",
    "embed_df = embed_df[['author_id', 'text', 'join_text', 'passage_key']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6cafd0f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "68b442da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8ec93475",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6530"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(embed_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "df392624",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/srtoner/.local/lib/python3.9/site-packages/sklearn/preprocessing/_label.py:115: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "n_classes = embed_df.author_id.nunique()\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "label_encoder=LabelEncoder()\n",
    "y= label_encoder.fit_transform(embed_df['author_id'].to_numpy(dtype='int32').reshape(-1,1))\n",
    "X = embed_df['passage_key']\n",
    "\n",
    "X_train, X_test, y_train, y_test = U.train_test_split(X, y, test_size=test_size,\n",
    "                                                        random_state=random_state,\n",
    "                                                        stratify=y)\n",
    "\n",
    "# Split train set into train and validation sets\n",
    "X_train, X_val, y_train, y_val = U.train_test_split(X_train, y_train, test_size=val_size/(1-test_size),\n",
    "                                                    random_state=random_state,\n",
    "                                                    stratify=y_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d3efdc7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_df['label'] = y\n",
    "\n",
    "train_set = set(X_train)\n",
    "val_set = set(X_val)\n",
    "test_set = set(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "16952596",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = embed_df[embed_df['passage_key'].apply(lambda S: S in train_set)]\n",
    "val = embed_df[embed_df['passage_key'].apply(lambda S: S in val_set)]\n",
    "test = embed_df[embed_df['passage_key'].apply(lambda S: S in test_set)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1e29b666",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.to_csv('train.csv', index=False)\n",
    "val.to_csv('val.csv', index=False)\n",
    "test.to_csv('test.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "25ee852c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author_id</th>\n",
       "      <th>text</th>\n",
       "      <th>join_text</th>\n",
       "      <th>passage_key</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1082</td>\n",
       "      <td>[Sland’ring creation with a false esteem:,    ...</td>\n",
       "      <td>Sland’ring creation with a false esteem:     Y...</td>\n",
       "      <td>PG1041_2425</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1082</td>\n",
       "      <td>[Giving him aid, my verse astonished., He, nor...</td>\n",
       "      <td>Giving him aid, my verse astonished. He, nor t...</td>\n",
       "      <td>PG1041_1725</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1082</td>\n",
       "      <td>[From where thou art why should I haste me the...</td>\n",
       "      <td>From where thou art why should I haste me then...</td>\n",
       "      <td>PG1041_1125</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1082</td>\n",
       "      <td>[, CXIII, , Since I left you, mine eye is in m...</td>\n",
       "      <td>CXIII  Since I left you, mine eye is in my mi...</td>\n",
       "      <td>PG1041_2175</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1082</td>\n",
       "      <td>[That tongue that tells the story of thy days,...</td>\n",
       "      <td>That tongue that tells the story of thy days, ...</td>\n",
       "      <td>PG1041_1875</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6518</th>\n",
       "      <td>1775</td>\n",
       "      <td>[is difficult to say, since it was only last n...</td>\n",
       "      <td>is difficult to say, since it was only last ni...</td>\n",
       "      <td>PG30445_1389</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6521</th>\n",
       "      <td>1775</td>\n",
       "      <td>[Tilsa and Tobene., , 'They are, if I may use ...</td>\n",
       "      <td>Tilsa and Tobene.  'They are, if I may use the...</td>\n",
       "      <td>PG30445_1139</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6524</th>\n",
       "      <td>1775</td>\n",
       "      <td>[cave. There was a noise of pots and pans., , ...</td>\n",
       "      <td>cave. There was a noise of pots and pans.  'Is...</td>\n",
       "      <td>PG30445_939</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6525</th>\n",
       "      <td>1775</td>\n",
       "      <td>[before the anticipation of the meal he would ...</td>\n",
       "      <td>before the anticipation of the meal he would d...</td>\n",
       "      <td>PG30445_1789</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6528</th>\n",
       "      <td>1775</td>\n",
       "      <td>[big.', , But Tilsa was not in the least disco...</td>\n",
       "      <td>big.'  But Tilsa was not in the least discoura...</td>\n",
       "      <td>PG30445_589</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3918 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      author_id                                               text  \\\n",
       "1          1082  [Sland’ring creation with a false esteem:,    ...   \n",
       "5          1082  [Giving him aid, my verse astonished., He, nor...   \n",
       "6          1082  [From where thou art why should I haste me the...   \n",
       "8          1082  [, CXIII, , Since I left you, mine eye is in m...   \n",
       "9          1082  [That tongue that tells the story of thy days,...   \n",
       "...         ...                                                ...   \n",
       "6518       1775  [is difficult to say, since it was only last n...   \n",
       "6521       1775  [Tilsa and Tobene., , 'They are, if I may use ...   \n",
       "6524       1775  [cave. There was a noise of pots and pans., , ...   \n",
       "6525       1775  [before the anticipation of the meal he would ...   \n",
       "6528       1775  [big.', , But Tilsa was not in the least disco...   \n",
       "\n",
       "                                              join_text   passage_key  label  \n",
       "1     Sland’ring creation with a false esteem:     Y...   PG1041_2425      0  \n",
       "5     Giving him aid, my verse astonished. He, nor t...   PG1041_1725      0  \n",
       "6     From where thou art why should I haste me then...   PG1041_1125      0  \n",
       "8      CXIII  Since I left you, mine eye is in my mi...   PG1041_2175      0  \n",
       "9     That tongue that tells the story of thy days, ...   PG1041_1875      0  \n",
       "...                                                 ...           ...    ...  \n",
       "6518  is difficult to say, since it was only last ni...  PG30445_1389      1  \n",
       "6521  Tilsa and Tobene.  'They are, if I may use the...  PG30445_1139      1  \n",
       "6524  cave. There was a noise of pots and pans.  'Is...   PG30445_939      1  \n",
       "6525  before the anticipation of the meal he would d...  PG30445_1789      1  \n",
       "6528  big.'  But Tilsa was not in the least discoura...   PG30445_589      1  \n",
       "\n",
       "[3918 rows x 5 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "daed2309",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "74003731",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset csv/default to /home/srtoner/.cache/huggingface/datasets/csv/default-3380779cca4b9e40/0.0.0...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c26432de6373474898e3a6fc9b0cfa96",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "187d7e2e2ae44cf79fa3d7f8972fc863",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset csv downloaded and prepared to /home/srtoner/.cache/huggingface/datasets/csv/default-3380779cca4b9e40/0.0.0. Subsequent calls will reuse this data.\n",
      "Downloading and preparing dataset csv/default to /home/srtoner/.cache/huggingface/datasets/csv/default-ccaaf7e8ee044be1/0.0.0...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c16bfb1b6bd4dd79d29a38b38ae861a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3e3644a6ad84129a1b5edaaa0e0258a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset csv downloaded and prepared to /home/srtoner/.cache/huggingface/datasets/csv/default-ccaaf7e8ee044be1/0.0.0. Subsequent calls will reuse this data.\n",
      "Downloading and preparing dataset csv/default to /home/srtoner/.cache/huggingface/datasets/csv/default-1316de57c83f67aa/0.0.0...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2e8167b695146e8b75f569a1c8b87ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a5eb224d2014593a2b7e49308493ea7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset csv downloaded and prepared to /home/srtoner/.cache/huggingface/datasets/csv/default-1316de57c83f67aa/0.0.0. Subsequent calls will reuse this data.\n"
     ]
    }
   ],
   "source": [
    "ds = {\n",
    "      'train' :  Dataset.from_csv('train.csv'),\n",
    "      'val' :  Dataset.from_csv('val.csv'),\n",
    "      'test' :  Dataset.from_csv('test.csv'),\n",
    "      }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "49c98c8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['author_id', 'text', 'join_text', 'passage_key', 'label'], dtype='object')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embed_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "77af4a2a",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at microsoft/MiniLM-L12-H384-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, DataCollatorWithPadding\n",
    "from transformers.integrations import TensorBoardCallback\n",
    "from transformers.trainer_callback import EarlyStoppingCallback\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "ds1 = {}\n",
    "\n",
    "BASE_MODEL = \"microsoft/MiniLM-L12-H384-uncased\"\n",
    "# BASE_MODEL = \"allenai/longformer-base-4096\"\n",
    "# BASE_MODEL = \"lreN5bs16\" # Learning Rate 2e-5, batch size 16\n",
    "LEARNING_RATE = 2e-5\n",
    "MAX_LENGTH = 510\n",
    "BATCH_SIZE = 16\n",
    "EPOCHS = 10\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(BASE_MODEL)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(BASE_MODEL, \n",
    "                                                           num_labels=n_classes,\n",
    "                                                           ignore_mismatched_sizes=True)\n",
    "\n",
    "def preprocess_function(examples, test = False):\n",
    "    # if not test:\n",
    "    label = examples[\"label\"] \n",
    "    examples = tokenizer(examples[\"join_text\"],\n",
    "                        truncation=True, \n",
    "                        padding=\"max_length\",\n",
    "                        max_length=MAX_LENGTH,\n",
    "                        return_tensors='pt')\n",
    "    \n",
    "    for key in examples:\n",
    "        examples[key] = examples[key].squeeze(0)\n",
    "  \n",
    "    # if not test:\n",
    "    examples[\"label\"] = torch.IntTensor([label])\n",
    "    examples = examples.to(device)\n",
    "    return examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "109e1b1b",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/3918 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1306 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1306 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for split in ds:\n",
    "    ds1[split] = ds[split].map(preprocess_function, \n",
    "                                remove_columns=['author_id', 'text', 'passage_key','join_text', 'label'])\n",
    "\n",
    "    ds1[split].set_format('pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e259538b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments, Trainer\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"output/\",\n",
    "    learning_rate=LEARNING_RATE,\n",
    "    per_device_train_batch_size=BATCH_SIZE,\n",
    "    per_device_eval_batch_size=BATCH_SIZE,\n",
    "    logging_steps = 1,\n",
    "    num_train_epochs=EPOCHS,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    metric_for_best_model=\"F1\",\n",
    "    greater_is_better=True,\n",
    "    load_best_model_at_end=True,\n",
    "    weight_decay=0.01,\n",
    "    report_to = 'tensorboard'\n",
    ")\n",
    "\n",
    "early_stop = EarlyStoppingCallback(1, 0.01)\n",
    "tb = TensorBoardCallback()\n",
    "\n",
    "\n",
    "from transformers import Trainer\n",
    "class CustomTrainer(Trainer):\n",
    "    def compute_loss(self, model, inputs, return_outputs=False):\n",
    "        labels = inputs.get(\"labels\")\n",
    "        outputs = model(**inputs)\n",
    "        logits = outputs.get(\"logits\")\n",
    "\n",
    "        loss_fct = nn.functional.cross_entropy\n",
    "        loss = loss_fct(logits.view(-1, n_classes), labels.view(-1))\n",
    "        return (loss, outputs) if return_outputs else loss\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f54be5ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score as f1s\n",
    "\n",
    "def compute_metrics_for_classification(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    labels = labels.reshape(-1, 1)\n",
    "    print(labels)\n",
    "    print(type(predictions))\n",
    "    \n",
    "    predicted_class = predictions.argmax(axis=1)\n",
    "    print(predicted_class)\n",
    "    f1 = f1s(labels, predicted_class,average = 'weighted')\n",
    "    print(f\"F1: {f1}\")\n",
    "    \n",
    "    return {\"F1\": f1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "774f2172",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = CustomTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=ds1[\"train\"],\n",
    "    eval_dataset=ds1[\"val\"],\n",
    "    compute_metrics=compute_metrics_for_classification,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "32adff86",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/srtoner/.local/lib/python3.9/site-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2450' max='2450' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2450/2450 10:55, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.263200</td>\n",
       "      <td>0.426725</td>\n",
       "      <td>0.828995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.171300</td>\n",
       "      <td>0.294253</td>\n",
       "      <td>0.890969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.389800</td>\n",
       "      <td>0.225322</td>\n",
       "      <td>0.946099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.329300</td>\n",
       "      <td>0.181360</td>\n",
       "      <td>0.961405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.161000</td>\n",
       "      <td>0.137182</td>\n",
       "      <td>0.970806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.043500</td>\n",
       "      <td>0.114216</td>\n",
       "      <td>0.977305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.023800</td>\n",
       "      <td>0.090360</td>\n",
       "      <td>0.980065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.035100</td>\n",
       "      <td>0.103922</td>\n",
       "      <td>0.977139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.014900</td>\n",
       "      <td>0.099015</td>\n",
       "      <td>0.975462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.015400</td>\n",
       "      <td>0.091856</td>\n",
       "      <td>0.979294</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0]\n",
      " [0]\n",
      " [0]\n",
      " ...\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n",
      "<class 'numpy.ndarray'>\n",
      "[0 0 0 ... 5 5 5]\n",
      "F1: 0.8289953762839195\n",
      "[[0]\n",
      " [0]\n",
      " [0]\n",
      " ...\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n",
      "<class 'numpy.ndarray'>\n",
      "[0 0 0 ... 1 1 1]\n",
      "F1: 0.8909686761303875\n",
      "[[0]\n",
      " [0]\n",
      " [0]\n",
      " ...\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n",
      "<class 'numpy.ndarray'>\n",
      "[0 0 0 ... 1 2 3]\n",
      "F1: 0.9460986714741068\n",
      "[[0]\n",
      " [0]\n",
      " [0]\n",
      " ...\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n",
      "<class 'numpy.ndarray'>\n",
      "[0 0 0 ... 1 2 3]\n",
      "F1: 0.9614045845618916\n",
      "[[0]\n",
      " [0]\n",
      " [0]\n",
      " ...\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n",
      "<class 'numpy.ndarray'>\n",
      "[0 0 0 ... 1 2 3]\n",
      "F1: 0.9708058328823721\n",
      "[[0]\n",
      " [0]\n",
      " [0]\n",
      " ...\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n",
      "<class 'numpy.ndarray'>\n",
      "[0 0 0 ... 1 2 3]\n",
      "F1: 0.977305412308145\n",
      "[[0]\n",
      " [0]\n",
      " [0]\n",
      " ...\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n",
      "<class 'numpy.ndarray'>\n",
      "[0 0 0 ... 1 2 3]\n",
      "F1: 0.9800652969654627\n",
      "[[0]\n",
      " [0]\n",
      " [0]\n",
      " ...\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n",
      "<class 'numpy.ndarray'>\n",
      "[0 0 0 ... 1 2 1]\n",
      "F1: 0.9771393483961665\n",
      "[[0]\n",
      " [0]\n",
      " [0]\n",
      " ...\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n",
      "<class 'numpy.ndarray'>\n",
      "[0 0 0 ... 1 2 3]\n",
      "F1: 0.9754615924365411\n",
      "[[0]\n",
      " [0]\n",
      " [0]\n",
      " ...\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n",
      "<class 'numpy.ndarray'>\n",
      "[0 0 0 ... 1 2 3]\n",
      "F1: 0.9792944802781371\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=2450, training_loss=0.19796143624057272, metrics={'train_runtime': 656.4687, 'train_samples_per_second': 59.683, 'train_steps_per_second': 3.732, 'total_flos': 2570996582128800.0, 'train_loss': 0.19796143624057272, 'epoch': 10.0})"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0eb49e32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0]\n",
      " [0]\n",
      " [0]\n",
      " ...\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n",
      "<class 'numpy.ndarray'>\n",
      "[0 0 0 ... 1 2 3]\n",
      "F1: 0.9800652969654627\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.09035958349704742,\n",
       " 'eval_F1': 0.9800652969654627,\n",
       " 'eval_runtime': 5.9532,\n",
       " 'eval_samples_per_second': 219.379,\n",
       " 'eval_steps_per_second': 13.774,\n",
       " 'epoch': 10.0}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a763af7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2b870122",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0]\n",
      " [0]\n",
      " [0]\n",
      " ...\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n",
      "<class 'numpy.ndarray'>\n",
      "[0 0 0 ... 1 1 1]\n",
      "F1: 0.9838759858061444\n"
     ]
    }
   ],
   "source": [
    "prediction = trainer.predict(ds1['test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "efeb66ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_model(f'hf_model_{suffix}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
