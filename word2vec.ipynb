{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b840f10d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils.data.dataloader import default_collate\n",
    "from gensim.models import KeyedVectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d09d327d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import pickle as pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9091a055",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('config.json', 'r') as f:\n",
    "    config = json.load(f)\n",
    "cwd = os.getcwd()\n",
    "os.chdir(config['REPODIR'])\n",
    "import Utils as U\n",
    "from Corpus import Corpus\n",
    "os.chdir(cwd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4a4bc389",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import init\n",
    "from tqdm.auto import tqdm, trange\n",
    "from collections import Counter\n",
    "import random\n",
    "from torch import optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37c61f32",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "641d5253",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8dd44443",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "class Word2Vec(nn.Module):\n",
    "    \n",
    "    def __init__(self, vocab_size, embedding_size):\n",
    "        super(Word2Vec, self).__init__()\n",
    "\n",
    "        self.vocab_size = vocab_size\n",
    "        self.embedding_size = embedding_size\n",
    "\n",
    "        self.target_embeddings = nn.Embedding(vocab_size, embedding_size)\n",
    "        self.context_embeddings = nn.Embedding(vocab_size, embedding_size)\n",
    "        self.init_emb(init_range=0.5/self.vocab_size)\n",
    "        \n",
    "    def init_emb(self, init_range):\n",
    "\n",
    "        init.uniform_(self.target_embeddings.weight, -init_range, init_range)\n",
    "        init.uniform_(self.context_embeddings.weight, -init_range, init_range)\n",
    "        \n",
    "    def forward(self, target_word_id, context_word_ids):\n",
    "        ''' \n",
    "        Predicts whether each context word was actually in the context of the target word.\n",
    "        The input is a tensor with a single target word's id and a tensor containing each\n",
    "        of the context words' ids (this includes both positive and negative examples).\n",
    "        '''\n",
    "\n",
    "        # Embedded target word\n",
    "        h = self.target_embeddings(target_word_id) # Shape: batch size, 1, embedding_dim\n",
    "\n",
    "        # Embedded Context words\n",
    "        u = self.context_embeddings(context_word_ids) # \n",
    "        u = u.transpose(1, 2)\n",
    "\n",
    "        product = torch.bmm(h,u)\n",
    "        sum = torch.sum(product, dim=1)\n",
    "        sig = torch.sigmoid(sum)\n",
    "        return sig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "138faf54",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def save(model, corpus, filename):\n",
    "    '''\n",
    "    Saves the model to the specified filename as a gensim KeyedVectors in the\n",
    "    text format so you can load it separately.\n",
    "    '''\n",
    "\n",
    "    # Creates an empty KeyedVectors with our embedding size\n",
    "    kv = KeyedVectors(vector_size=model.embedding_size)        \n",
    "    vectors = []\n",
    "    words = []\n",
    "    # Get the list of words/vectors in a consistent order\n",
    "    for index in trange(model.target_embeddings.num_embeddings):\n",
    "        word = corpus.index_to_word[index]\n",
    "        vectors.append(model.target_embeddings(torch.LongTensor([index]).to(device)).cpu().detach().numpy()[0])\n",
    "        words.append(word)\n",
    "\n",
    "    # Fills the KV object with our data in the right order\n",
    "    kv.add_vectors(words, vectors) \n",
    "    kv.save_word2vec_format(filename, binary=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "197abb02",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(config['REPODIR'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2d98f64",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14ec92e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on: cuda:0\n"
     ]
    }
   ],
   "source": [
    "random.seed(1234)\n",
    "np.random.seed(1234)\n",
    "torch.manual_seed(1234)\n",
    "suffix = 'baby'\n",
    "save_pickle = True\n",
    "torch.set_default_dtype(torch.float32)\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "#     device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "kwargs = {'num_workers': 1, 'pin_memory': True} if device == \"cuda:0\" or device == 'mps' else {}\n",
    "\n",
    "# collate_func = default_collate\n",
    "collate_func = lambda x: tuple(x_.to(device) for x_ in default_collate(x)) if device != \"cpu\" else default_collate\n",
    "print(\"Running on: \" + str(device))\n",
    "\n",
    "corpus = U.load_file('corpus' + suffix + '.pkl','pkl', config['DATADIR'])\n",
    "training_data = U.load_file('training_data' + suffix + '.pkl','pkl', config['DATADIR'])\n",
    "# \n",
    "\n",
    "\n",
    "loss_period = 100\n",
    "model = Word2Vec(len(corpus.word_to_index), 50)\n",
    "model = model.to(device)\n",
    "writer = SummaryWriter()\n",
    "loss_function = nn.BCELoss()\n",
    "optimizer = optim.AdamW(model.parameters(), lr = 5e-3, weight_decay = 1e-3)\n",
    "train_data = DataLoader(training_data, batch_size=512, shuffle=True, \n",
    "            collate_fn=collate_func,\n",
    "            **kwargs)\n",
    "\n",
    "n_epochs = 2\n",
    "loss_idx = 0\n",
    "loss_record = []\n",
    "model.train()\n",
    "\n",
    "for epoch in tqdm(range(n_epochs)):\n",
    "    loss_sum = 0\n",
    "\n",
    "    for step, data in tqdm(enumerate(train_data)):\n",
    "        model.train()\n",
    "        model.zero_grad()\n",
    "        target_ids, context_ids, labels = data\n",
    "\n",
    "        output = model(target_ids, context_ids)\n",
    "        loss = loss_function(output, labels.float())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        loss_sum += loss.item()\n",
    "\n",
    "        if not step % loss_period and step:\n",
    "            writer.add_scalar(\"Loss\", loss_sum, loss_idx)\n",
    "            loss_record.append(loss_sum)\n",
    "\n",
    "            loss_sum = 0\n",
    "            loss_idx += 1\n",
    "\n",
    "model.eval()\n",
    "\n",
    "save(model, corpus, 'output_' + suffix)\n",
    "\n",
    "corpus_data = {\n",
    "'word2idx' : corpus.word_to_index,\n",
    "'idx2word' : corpus.index_to_word,\n",
    "'word_counts' : corpus.word_counts,\n",
    "'neg_sample' : corpus.negative_sampling_table\n",
    "}\n",
    "\n",
    "torch.save(optimizer.state_dict(), 'trained_opt_' + suffix)\n",
    "torch.save(model.state_dict(), 'trained_model_' + suffix)\n",
    "\n",
    "\n",
    "with open('corpus_data_' + suffix + '.pkl', 'wb') as f:\n",
    "    pkl.dump(corpus_data, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed292d06",
   "metadata": {},
   "outputs": [],
   "source": [
    "        "
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
